{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of CS286CazymesGridSearch.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "17m6pvLm0hsH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6389cf0a-47c0-4cdb-b80b-12f83d6dd9fc"
      },
      "source": [
        "# CS 286 Project Spring 2021 under Professor  \n",
        "#\n",
        "# David Bui and Sushant Mane\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nD217Be2d0lj"
      },
      "source": [
        "import numpy as np\n",
        "import copy\n",
        "import pickle\n",
        "import random\n",
        "from os import listdir, walk\n",
        "from os.path import isfile, join\n",
        "import io\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5E9fojLYROmx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "4a1f407a-c9b4-40db-b7ea-6a5233e6c8a9"
      },
      "source": [
        "# To run must go through folder and uncomment certain blocks of code\n",
        "# basePath in drive should be changed according to how folders are placed \n",
        "basePath = '/content/drive/MyDrive/286Project/'\n",
        "\n",
        "# sequence fasta file folders\n",
        "no_react_folder = basePath + 'fastaNoReaction'\n",
        "avicel_folder = basePath + 'fastaAvicel'\n",
        "cmc_folder = basePath + 'fastaCMC'\n",
        "lich_folder = basePath + 'fastaLichenan'\n",
        "miscanthus_folder = basePath + 'fastaMiscanthus'\n",
        "switchgrass_folder = basePath + 'fastaSwitchgrass'\n",
        "xylan_folder = basePath + 'fastaXylan'\n",
        "\n",
        "# folders containing sequences that did not react to the substrate in name\n",
        "no_react_not_folder = basePath + 'fastaNoReactionNot'\n",
        "avicel_not_folder = basePath + 'fastaAvicelNot'\n",
        "cmc_not_folder = basePath + 'fastaCMCNot'\n",
        "lich_not_folder = basePath + 'fastaLichenanNot'\n",
        "miscanthus_not_folder = basePath + 'fastaMiscanthusNot'\n",
        "switchgrass_not_folder = basePath + 'fastaSwitchgrassNot'\n",
        "xylan_not_folder = basePath + 'fastaXylanNot'\n",
        "\n",
        "savePath = basePath + 'mlp_cmc_model.sav' # path to save mlp models\n",
        "\n",
        "\n",
        "# uncomment one pair below train whichever model or substrate focus\n",
        "folders_to_classify = []\n",
        "\n",
        "folders_to_classify.append(no_react_folder)\n",
        "folders_to_classify.append(no_react_not_folder)\n",
        "\n",
        "# folders_to_classify.append(avicel_folder)\n",
        "# folders_to_classify.append(avicel_not_folder)\n",
        "\n",
        "# folders_to_classify.append(cmc_folder)\n",
        "# folders_to_classify.append(cmc_not_folder)\n",
        "\n",
        "# folders_to_classify.append(lich_folder)\n",
        "# folders_to_classify.append(lich_not_folder)\n",
        "\n",
        "# folders_to_classify.append(miscanthus_folder)\n",
        "# folders_to_classify.append(miscanthus_not_folder)\n",
        "\n",
        "# folders_to_classify.append(switchgrass_folder)\n",
        "# folders_to_classify.append(switchgrass_not_folder)\n",
        "\n",
        "# folders_to_classify.append(xylan_folder)\n",
        "# folders_to_classify.append(xylan_not_folder)\n",
        "\n",
        "\n",
        "# functions below are for parsing and adding the sequences in each fasta file\n",
        "# to a pandas dataframe\n",
        "\n",
        "#\n",
        "# Parse files and add to a id# -> sequence dictionary IDToSequence\n",
        "#\n",
        "def get_dir_files(dir): \n",
        "  files = [f for f in listdir(dir) if isfile(join(dir, f))]\n",
        "  return files\n",
        "\n",
        "def seq_map(folder, files): \n",
        "  IDToSequence = {}\n",
        "  for next in files:\n",
        "    nextPath = folder + '/'+ next\n",
        "    sequenceName = next[:len(next)-4] # remove the .txt extension\n",
        "    text_file = open(nextPath, \"r\")\n",
        "    lines = text_file.readlines()\n",
        "    sliced = lines[1:]\n",
        "    combined = ''.join(sliced)\n",
        "    IDToSequence[sequenceName] = combined.replace('\\n', '').replace('\\r', '')\n",
        "  return IDToSequence\n",
        "\n",
        "def seq_arr(folder, files):\n",
        "  seq = []\n",
        "  for next in files:\n",
        "    nextPath = folder + '/'+ next\n",
        "    sequenceName = next[:len(next)-4] # remove the .txt extension\n",
        "    text_file = open(nextPath, \"r\")\n",
        "    lines = text_file.readlines()\n",
        "    sliced = lines[1:]\n",
        "    combined = ''.join(sliced)\n",
        "    seq.append(combined.replace('\\n', '').replace('\\r', ''))\n",
        "  return seq\n",
        "\n",
        "\n",
        "def print_seq(seq):\n",
        "  for next in seq:\n",
        "    name = 'Sequence ID: ' + str(next)\n",
        "    sequence = 'Sequence below: \\n' + seq[next]  + '\\n'\n",
        "    print(name)\n",
        "    print(sequence)\n",
        "\n",
        "def get_seq(data_folders = []):\n",
        "  data_files = []\n",
        "  for next in data_folders:\n",
        "    data_files.append(get_dir_files(next))\n",
        "  fasta_seq = []\n",
        "  f_len = len(data_folders)\n",
        "  for i in range(f_len):\n",
        "    fasta_seq.append(seq_arr(data_folders[i], data_files[i]))\n",
        "  return fasta_seq\n",
        "\n",
        "# gather sequences\n",
        "def addToData(lists): \n",
        "  classes = 0\n",
        "  data = {'sequence': [], 'class': []}\n",
        "  for seq in lists:\n",
        "    prev = data['sequence']\n",
        "    conca = prev + seq \n",
        "    seq_len = len(seq)\n",
        "    data.update({'sequence': conca})\n",
        "    class_list = []\n",
        "    for i in range(seq_len):\n",
        "      class_list.append(classes)\n",
        "    prev_class = data['class']\n",
        "    both_class = prev_class + class_list\n",
        "    data.update({'class': both_class})\n",
        "    classes = classes + 1\n",
        "  return data\n",
        "\n",
        "\n",
        "lists_of_seq = get_seq(folders_to_classify)\n",
        "data = addToData(lists_of_seq)\n",
        "cazy_data = pd.DataFrame(data)\n",
        "cazy_data.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sequence</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TTGAATATCCCTGAGAGCGAGAACGCAACGGCTGATTTCCTCGATG...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ATGAAAAGGACAAAAGGAAAATTTATCATATCAGCCAATGAAATAG...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>ATGAGCGGCAAGGCAGTTCTCACGCTTGAAGCTCCGATGGTCTATG...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>ATGAAAAAGAGGATTGTAAGTGCAATACTCGCAGGTTCCATGCTCT...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>ATGAATATAAACCGTCTTATATTTCCGGGTTTTTGGTTCGGCAAAA...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            sequence  class\n",
              "0  TTGAATATCCCTGAGAGCGAGAACGCAACGGCTGATTTCCTCGATG...      0\n",
              "1  ATGAAAAGGACAAAAGGAAAATTTATCATATCAGCCAATGAAATAG...      0\n",
              "2  ATGAGCGGCAAGGCAGTTCTCACGCTTGAAGCTCCGATGGTCTATG...      0\n",
              "3  ATGAAAAAGAGGATTGTAAGTGCAATACTCGCAGGTTCCATGCTCT...      0\n",
              "4  ATGAATATAAACCGTCTTATATTTCCGGGTTTTTGGTTCGGCAAAA...      0"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qV42xeOLsP6r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "74a56231-e93a-4d52-81e7-4ca21cd0b6b6"
      },
      "source": [
        "# begin code for worksheet 6 baysian\n",
        "# function to convert sequence strings into k-mer words, default size = 6 (hexamer words)\n",
        "def getKmers(sequence, size=6):\n",
        "    return [sequence[x:x+size].lower() for x in range(len(sequence) - size + 1)]\n",
        "cazy_data['words'] = cazy_data.apply(lambda x: getKmers(x['sequence']), axis=1)\n",
        "cazy_data = cazy_data.drop('sequence', axis=1)\n",
        "\n",
        "cazy_texts = list(cazy_data['words'])\n",
        "for item in range(len(cazy_texts)):\n",
        "    cazy_texts[item] = ' '.join(cazy_texts[item])\n",
        "y_data = cazy_data.iloc[:, 0].values    \n",
        "\n",
        "y_data"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
              "       0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
              "       1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "s5p0tWK0slIx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "04964d4f-00a0-41c7-95ec-9d1efbbbd393"
      },
      "source": [
        "# Creating the Bag of Words model using CountVectorizer()\n",
        "# This is equivalent to k-mer counting\n",
        "# The n-gram size of 4 was previously determined by testing\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "cv = CountVectorizer(ngram_range=(4,4))\n",
        "X_cazy = cv.fit_transform(cazy_texts)\n",
        "print(X_cazy.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(81, 91347)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VYFu4T7Eswlk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46abc49c-5359-43f6-cd5d-5fe80d694213"
      },
      "source": [
        "# Splitting the human dataset into the training set and test set\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_cazy, \n",
        "                                                    y_data, \n",
        "                                                    test_size = 0.25, random_state = 42) \n",
        "\n",
        "print(\"TRAINING X train and y train shape\")\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "print(\"TESTING X test and y test shape\")\n",
        "print(X_test.shape)\n",
        "print(y_test.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "TRAINING X train and y train shape\n",
            "(60, 91347)\n",
            "(60,)\n",
            "TESTING X test and y test shape\n",
            "(21, 91347)\n",
            "(21,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RIYv_BPcsz52",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b44087a5-34e5-48cd-eabf-0f609429f10e"
      },
      "source": [
        "# various tested ML models\n",
        "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score\n",
        "from sklearn.model_selection import ParameterGrid\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.gaussian_process.kernels import RBF\n",
        "from sklearn.gaussian_process import GaussianProcessClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Best mlp models found through grid search uncomment depending on \n",
        "\n",
        "# # no reaction enzymes and enzymes with any reactions: 1.00 accuracy in grid search\n",
        "classifier = MLPClassifier(activation='relu', hidden_layer_sizes=(10,10), learning_rate='adaptive', max_iter=1000000, solver='lbfgs', shuffle=False)\n",
        "\n",
        "# # enzymes with avicel versus no avicel reactions 0.917: accuracy in grid search\n",
        "# classifier = MLPClassifier(activation='relu', hidden_layer_sizes=(10,10,10), learning_rate='constant', max_iter=1000000, solver='lbfgs', shuffle=True)\n",
        "\n",
        "# # enzymes with cmc versus no cmc reactions: 0.8333 accuracy in grid search\n",
        "# classifier = MLPClassifier(activation='relu', hidden_layer_sizes=(20,20,20), learning_rate='adaptive', max_iter=1000000, solver='lbfgs', shuffle=True)\n",
        "\n",
        "# # enzymes with lich versus not lich reactions: 1.000 accuracy in grid search\n",
        "# classifier = MLPClassifier(activation='relu', hidden_layer_sizes=(10,10), learning_rate='constant', max_iter=1000000, solver='lbfgs', shuffle=True)\n",
        "\n",
        "# # enzymes with miscanthus versus no miscanthus reactions 0.857 accuracy in grid search\n",
        "# classifier = MLPClassifier(activation='relu', hidden_layer_sizes=(10,10), learning_rate='constant', max_iter=1000000, solver='lbfgs', shuffle=True)\n",
        "\n",
        "# # enzymes with switchgrass versus  no switchgrass reactions:  0.857 accuracy in grid search\n",
        "# classifier = MLPClassifier(activation='relu', hidden_layer_sizes=(10,10), learning_rate='constant', max_iter=1000000, solver='lbfgs', shuffle=True)\n",
        "\n",
        "# # enzymes with xylan versus no xylan reactions: 1.000 accuracy in grid search\n",
        "# classifier = MLPClassifier(activation='relu', hidden_layer_sizes=(10,10), learning_rate='constant', max_iter=1000000, solver='sgd', shuffle=False)\n",
        "\n",
        "mlp = MLPClassifier()\n",
        "\n",
        "mlp_params = {\n",
        "'learning_rate': [\"constant\", \"adaptive\", \"invscaling\"],\n",
        "'hidden_layer_sizes': [(10,10,),(20,20,),(30,30,),(10,10,10),(20,20,20), (30,30,30),(50,50),],\n",
        "'solver': ['lbfgs','sgd', 'adam'],\n",
        "'activation': [\"relu\", \"logistic\", \"tanh\"],\n",
        "'max_iter' : [1000],\n",
        "'shuffle': [False, True]\n",
        "}\n",
        "\n",
        "\n",
        "gridMLP = GridSearchCV(estimator=mlp, param_grid=mlp_params, scoring='accuracy', verbose=10)\n",
        "\n",
        "\n",
        "# Uncomment below to run a MLP grid search on the current dataset. \n",
        "# Gridsearch accuracy is based on Training dataset only.\n",
        "# WARNING This will take 1 - 2 to run uunder current parameter grid.\n",
        "\n",
        "\n",
        "# gridMLP.fit(X_train, y_train)\n",
        "# print('Best mlp')\n",
        "# print('Best parameters found:\\n', gridMLP.best_params_)\n",
        "# print(\"Best score: \",gridMLP.best_score_)\n",
        "\n",
        "classifier.fit(X_train, y_train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MLPClassifier(activation='relu', alpha=0.0001, batch_size='auto', beta_1=0.9,\n",
              "              beta_2=0.999, early_stopping=False, epsilon=1e-08,\n",
              "              hidden_layer_sizes=(10, 10), learning_rate='adaptive',\n",
              "              learning_rate_init=0.001, max_fun=15000, max_iter=1000000,\n",
              "              momentum=0.9, n_iter_no_change=10, nesterovs_momentum=True,\n",
              "              power_t=0.5, random_state=None, shuffle=False, solver='lbfgs',\n",
              "              tol=0.0001, validation_fraction=0.1, verbose=False,\n",
              "              warm_start=False)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "68HBRMSIs7cc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "612fc83b-3af9-43b6-8b7f-cba36979716f"
      },
      "source": [
        "# The code below loops until a MLP classifier is found with > 90 % accuracy on the testing dataset.\n",
        "\n",
        "y_pred = classifier.predict(X_test)\n",
        "print(y_test)\n",
        "print(y_pred)\n",
        "print(\"Confusion matrix\\n\")\n",
        "print(pd.crosstab(pd.Series(y_test, name='Actual'), pd.Series(y_pred, name='Predicted')))\n",
        "def get_metrics(y_test, y_predicted):\n",
        "    accuracy = accuracy_score(y_test, y_predicted)\n",
        "    precision = precision_score(y_test, y_predicted, average='weighted')\n",
        "    recall = recall_score(y_test, y_predicted, average='weighted')\n",
        "    f1 = f1_score(y_test, y_predicted, average='weighted')\n",
        "    return accuracy, precision, recall, f1\n",
        "accuracy, precision, recall, f1 = get_metrics(y_test, y_pred)\n",
        "print(\"accuracy = %.3f \\nprecision = %.3f \\nrecall = %.3f \\nf1 = %.3f\" % (accuracy, precision, recall, f1))\n",
        "\n",
        "# loop here to do random restarts\n",
        "while accuracy < 0.91 or accuracy == 1.00:\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X_cazy, \n",
        "                                                    y_data, \n",
        "                                                    test_size = 0.20) #random_state = 42\n",
        "  classifier.fit(X_train, y_train)\n",
        "  y_pred = classifier.predict(X_test)\n",
        "  accuracy, precision, recall, f1 = get_metrics(y_test, y_pred)\n",
        "  print(\"Confusion matrix\\n\")\n",
        "  print(pd.crosstab(pd.Series(y_test, name='Actual'), pd.Series(y_pred, name='Predicted')))\n",
        "  print(\"accuracy = %.3f \\nprecision = %.3f \\nrecall = %.3f \\nf1 = %.3f\" % (accuracy, precision, recall, f1))\n",
        "  if (accuracy >= 0.900 and precision >= 0.910) and not (accuracy == 1.00 or precision == 1.00):\n",
        "    break\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[0 0 0 0 0 0 0 1 0 0 1 0 1 1 1 1 1 1 1 1 0]\n",
            "[1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1]\n",
            "Confusion matrix\n",
            "\n",
            "Predicted  0   1\n",
            "Actual          \n",
            "0          1  10\n",
            "1          0  10\n",
            "accuracy = 0.524 \n",
            "precision = 0.762 \n",
            "recall = 0.524 \n",
            "f1 = 0.405\n",
            "Confusion matrix\n",
            "\n",
            "Predicted  0  1\n",
            "Actual         \n",
            "0          4  5\n",
            "1          0  8\n",
            "accuracy = 0.706 \n",
            "precision = 0.819 \n",
            "recall = 0.706 \n",
            "f1 = 0.684\n",
            "Confusion matrix\n",
            "\n",
            "Predicted  0   1\n",
            "Actual          \n",
            "0          4   3\n",
            "1          0  10\n",
            "accuracy = 0.824 \n",
            "precision = 0.864 \n",
            "recall = 0.824 \n",
            "f1 = 0.811\n",
            "Confusion matrix\n",
            "\n",
            "Predicted  0  1\n",
            "Actual         \n",
            "0          6  1\n",
            "1          2  8\n",
            "accuracy = 0.824 \n",
            "precision = 0.832 \n",
            "recall = 0.824 \n",
            "f1 = 0.825\n",
            "Confusion matrix\n",
            "\n",
            "Predicted  0   1\n",
            "Actual          \n",
            "0          1   3\n",
            "1          2  11\n",
            "accuracy = 0.706 \n",
            "precision = 0.679 \n",
            "recall = 0.706 \n",
            "f1 = 0.690\n",
            "Confusion matrix\n",
            "\n",
            "Predicted  0  1\n",
            "Actual         \n",
            "0          3  5\n",
            "1          1  8\n",
            "accuracy = 0.647 \n",
            "precision = 0.679 \n",
            "recall = 0.647 \n",
            "f1 = 0.620\n",
            "Confusion matrix\n",
            "\n",
            "Predicted  0  1\n",
            "Actual         \n",
            "0          6  1\n",
            "1          3  7\n",
            "accuracy = 0.765 \n",
            "precision = 0.789 \n",
            "recall = 0.765 \n",
            "f1 = 0.766\n",
            "Confusion matrix\n",
            "\n",
            "Predicted  0  1\n",
            "Actual         \n",
            "0          2  5\n",
            "1          1  9\n",
            "accuracy = 0.647 \n",
            "precision = 0.653 \n",
            "recall = 0.647 \n",
            "f1 = 0.606\n",
            "Confusion matrix\n",
            "\n",
            "Predicted  0  1\n",
            "Actual         \n",
            "0          5  2\n",
            "1          3  7\n",
            "accuracy = 0.706 \n",
            "precision = 0.715 \n",
            "recall = 0.706 \n",
            "f1 = 0.708\n",
            "Confusion matrix\n",
            "\n",
            "Predicted  0  1\n",
            "Actual         \n",
            "0          1  8\n",
            "1          0  8\n",
            "accuracy = 0.529 \n",
            "precision = 0.765 \n",
            "recall = 0.529 \n",
            "f1 = 0.420\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix\n",
            "\n",
            "Predicted   1\n",
            "Actual       \n",
            "0           7\n",
            "1          10\n",
            "accuracy = 0.588 \n",
            "precision = 0.346 \n",
            "recall = 0.588 \n",
            "f1 = 0.436\n",
            "Confusion matrix\n",
            "\n",
            "Predicted  0  1\n",
            "Actual         \n",
            "0          2  5\n",
            "1          1  9\n",
            "accuracy = 0.647 \n",
            "precision = 0.653 \n",
            "recall = 0.647 \n",
            "f1 = 0.606\n",
            "Confusion matrix\n",
            "\n",
            "Predicted  0  1\n",
            "Actual         \n",
            "0          3  4\n",
            "1          1  9\n",
            "accuracy = 0.706 \n",
            "precision = 0.716 \n",
            "recall = 0.706 \n",
            "f1 = 0.685\n",
            "Confusion matrix\n",
            "\n",
            "Predicted  0  1\n",
            "Actual         \n",
            "0          3  9\n",
            "1          0  5\n",
            "accuracy = 0.471 \n",
            "precision = 0.811 \n",
            "recall = 0.471 \n",
            "f1 = 0.437\n",
            "Confusion matrix\n",
            "\n",
            "Predicted  0  1\n",
            "Actual         \n",
            "0          4  1\n",
            "1          3  9\n",
            "accuracy = 0.765 \n",
            "precision = 0.803 \n",
            "recall = 0.765 \n",
            "f1 = 0.774\n",
            "Confusion matrix\n",
            "\n",
            "Predicted  0  1\n",
            "Actual         \n",
            "0          8  1\n",
            "1          5  3\n",
            "accuracy = 0.647 \n",
            "precision = 0.679 \n",
            "recall = 0.647 \n",
            "f1 = 0.620\n",
            "Confusion matrix\n",
            "\n",
            "Predicted  0  1\n",
            "Actual         \n",
            "0          6  0\n",
            "1          6  5\n",
            "accuracy = 0.647 \n",
            "precision = 0.824 \n",
            "recall = 0.647 \n",
            "f1 = 0.640\n",
            "Confusion matrix\n",
            "\n",
            "Predicted  0  1\n",
            "Actual         \n",
            "0          1  8\n",
            "1          1  7\n",
            "accuracy = 0.471 \n",
            "precision = 0.484 \n",
            "recall = 0.471 \n",
            "f1 = 0.383\n",
            "Confusion matrix\n",
            "\n",
            "Predicted  0   1\n",
            "Actual          \n",
            "0          1   6\n",
            "1          0  10\n",
            "accuracy = 0.647 \n",
            "precision = 0.779 \n",
            "recall = 0.647 \n",
            "f1 = 0.555\n",
            "Confusion matrix\n",
            "\n",
            "Predicted  0  1\n",
            "Actual         \n",
            "0          4  5\n",
            "1          0  8\n",
            "accuracy = 0.706 \n",
            "precision = 0.819 \n",
            "recall = 0.706 \n",
            "f1 = 0.684\n",
            "Confusion matrix\n",
            "\n",
            "Predicted  0  1\n",
            "Actual         \n",
            "0          3  4\n",
            "1          5  5\n",
            "accuracy = 0.471 \n",
            "precision = 0.481 \n",
            "recall = 0.471 \n",
            "f1 = 0.474\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix\n",
            "\n",
            "Predicted  1\n",
            "Actual      \n",
            "0          8\n",
            "1          9\n",
            "accuracy = 0.529 \n",
            "precision = 0.280 \n",
            "recall = 0.529 \n",
            "f1 = 0.367\n",
            "Confusion matrix\n",
            "\n",
            "Predicted  0  1\n",
            "Actual         \n",
            "0          3  0\n",
            "1          7  7\n",
            "accuracy = 0.588 \n",
            "precision = 0.876 \n",
            "recall = 0.588 \n",
            "f1 = 0.630\n",
            "Confusion matrix\n",
            "\n",
            "Predicted  0  1\n",
            "Actual         \n",
            "0          0  7\n",
            "1          1  9\n",
            "accuracy = 0.529 \n",
            "precision = 0.331 \n",
            "recall = 0.529 \n",
            "f1 = 0.407\n",
            "Confusion matrix\n",
            "\n",
            "Predicted  0  1\n",
            "Actual         \n",
            "0          1  8\n",
            "1          0  8\n",
            "accuracy = 0.529 \n",
            "precision = 0.765 \n",
            "recall = 0.529 \n",
            "f1 = 0.420\n",
            "Confusion matrix\n",
            "\n",
            "Predicted  0  1\n",
            "Actual         \n",
            "0          3  4\n",
            "1          1  9\n",
            "accuracy = 0.706 \n",
            "precision = 0.716 \n",
            "recall = 0.706 \n",
            "f1 = 0.685\n",
            "Confusion matrix\n",
            "\n",
            "Predicted  0   1\n",
            "Actual          \n",
            "0          1   5\n",
            "1          0  11\n",
            "accuracy = 0.706 \n",
            "precision = 0.798 \n",
            "recall = 0.706 \n",
            "f1 = 0.628\n",
            "Confusion matrix\n",
            "\n",
            "Predicted  0  1\n",
            "Actual         \n",
            "0          5  6\n",
            "1          4  2\n",
            "accuracy = 0.412 \n",
            "precision = 0.448 \n",
            "recall = 0.412 \n",
            "f1 = 0.424\n",
            "Confusion matrix\n",
            "\n",
            "Predicted  0  1\n",
            "Actual         \n",
            "0          9  3\n",
            "1          3  2\n",
            "accuracy = 0.647 \n",
            "precision = 0.647 \n",
            "recall = 0.647 \n",
            "f1 = 0.647\n",
            "Confusion matrix\n",
            "\n",
            "Predicted  0  1\n",
            "Actual         \n",
            "0          5  0\n",
            "1          9  3\n",
            "accuracy = 0.471 \n",
            "precision = 0.811 \n",
            "recall = 0.471 \n",
            "f1 = 0.437\n",
            "Confusion matrix\n",
            "\n",
            "Predicted  0   1\n",
            "Actual          \n",
            "0          1   6\n",
            "1          0  10\n",
            "accuracy = 0.647 \n",
            "precision = 0.779 \n",
            "recall = 0.647 \n",
            "f1 = 0.555\n",
            "Confusion matrix\n",
            "\n",
            "Predicted  0  1\n",
            "Actual         \n",
            "0          4  2\n",
            "1          5  6\n",
            "accuracy = 0.588 \n",
            "precision = 0.642 \n",
            "recall = 0.588 \n",
            "f1 = 0.597\n",
            "Confusion matrix\n",
            "\n",
            "Predicted  0   1\n",
            "Actual          \n",
            "0          0   6\n",
            "1          1  10\n",
            "accuracy = 0.588 \n",
            "precision = 0.404 \n",
            "recall = 0.588 \n",
            "f1 = 0.479\n",
            "Confusion matrix\n",
            "\n",
            "Predicted  0  1\n",
            "Actual         \n",
            "0          2  6\n",
            "1          1  8\n",
            "accuracy = 0.588 \n",
            "precision = 0.616 \n",
            "recall = 0.588 \n",
            "f1 = 0.539\n",
            "Confusion matrix\n",
            "\n",
            "Predicted  0   1\n",
            "Actual          \n",
            "0          4   2\n",
            "1          1  10\n",
            "accuracy = 0.824 \n",
            "precision = 0.822 \n",
            "recall = 0.824 \n",
            "f1 = 0.819\n",
            "Confusion matrix\n",
            "\n",
            "Predicted  0  1\n",
            "Actual         \n",
            "0          2  7\n",
            "1          0  8\n",
            "accuracy = 0.588 \n",
            "precision = 0.780 \n",
            "recall = 0.588 \n",
            "f1 = 0.520\n",
            "Confusion matrix\n",
            "\n",
            "Predicted  0   1\n",
            "Actual          \n",
            "0          2   4\n",
            "1          0  11\n",
            "accuracy = 0.765 \n",
            "precision = 0.827 \n",
            "recall = 0.765 \n",
            "f1 = 0.724\n",
            "Confusion matrix\n",
            "\n",
            "Predicted  0   1\n",
            "Actual          \n",
            "0          3   3\n",
            "1          1  10\n",
            "accuracy = 0.765 \n",
            "precision = 0.762 \n",
            "recall = 0.765 \n",
            "f1 = 0.751\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Confusion matrix\n",
            "\n",
            "Predicted   1\n",
            "Actual       \n",
            "0           7\n",
            "1          10\n",
            "accuracy = 0.588 \n",
            "precision = 0.346 \n",
            "recall = 0.588 \n",
            "f1 = 0.436\n",
            "Confusion matrix\n",
            "\n",
            "Predicted  0  1\n",
            "Actual         \n",
            "0          2  5\n",
            "1          1  9\n",
            "accuracy = 0.647 \n",
            "precision = 0.653 \n",
            "recall = 0.647 \n",
            "f1 = 0.606\n",
            "Confusion matrix\n",
            "\n",
            "Predicted  0  1\n",
            "Actual         \n",
            "0          5  1\n",
            "1          8  3\n",
            "accuracy = 0.471 \n",
            "precision = 0.621 \n",
            "recall = 0.471 \n",
            "f1 = 0.445\n",
            "Confusion matrix\n",
            "\n",
            "Predicted  0  1\n",
            "Actual         \n",
            "0          5  1\n",
            "1          2  9\n",
            "accuracy = 0.824 \n",
            "precision = 0.834 \n",
            "recall = 0.824 \n",
            "f1 = 0.826\n",
            "Confusion matrix\n",
            "\n",
            "Predicted  0  1\n",
            "Actual         \n",
            "0          6  0\n",
            "1          8  3\n",
            "accuracy = 0.529 \n",
            "precision = 0.798 \n",
            "recall = 0.529 \n",
            "f1 = 0.489\n",
            "Confusion matrix\n",
            "\n",
            "Predicted  0  1\n",
            "Actual         \n",
            "0          1  8\n",
            "1          1  7\n",
            "accuracy = 0.471 \n",
            "precision = 0.484 \n",
            "recall = 0.471 \n",
            "f1 = 0.383\n",
            "Confusion matrix\n",
            "\n",
            "Predicted  0   1\n",
            "Actual          \n",
            "0          0   3\n",
            "1          1  13\n",
            "accuracy = 0.765 \n",
            "precision = 0.669 \n",
            "recall = 0.765 \n",
            "f1 = 0.714\n",
            "Confusion matrix\n",
            "\n",
            "Predicted  0  1\n",
            "Actual         \n",
            "0          6  1\n",
            "1          1  9\n",
            "accuracy = 0.882 \n",
            "precision = 0.882 \n",
            "recall = 0.882 \n",
            "f1 = 0.882\n",
            "Confusion matrix\n",
            "\n",
            "Predicted  0  1\n",
            "Actual         \n",
            "0          6  1\n",
            "1          3  7\n",
            "accuracy = 0.765 \n",
            "precision = 0.789 \n",
            "recall = 0.765 \n",
            "f1 = 0.766\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PUmwwO4M7Npy"
      },
      "source": [
        "print(\"\\n break \\n\")\n",
        "print(\"Confusion matrix\\n\")\n",
        "print(pd.crosstab(pd.Series(y_test, name='Actual'), pd.Series(y_pred, name='Predicted')))\n",
        "print(\"accuracy = %.3f \\nprecision = %.3f \\nrecall = %.3f \\nf1 = %.3f\" % (accuracy, precision, recall, f1))\n",
        "pickle.dump(classifier, open(savePath, 'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}